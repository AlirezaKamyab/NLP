{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc8a618a-7393-479c-93d9-9ce1b7c0bb8a",
   "metadata": {},
   "source": [
    "# Text Generation using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac195c9-224b-414a-9d3f-29c2ba2ade5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 14:01:35.824209: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-17 14:01:35.824237: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-17 14:01:35.825215: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.config.optimizer.set_jit(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b09e4-fe34-401b-a71b-64ecbf1f3046",
   "metadata": {},
   "source": [
    "## Load Shahnameh Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ca7846-7a8a-4be1-b60c-1fa8d2eec723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Part</th>\n",
       "      <th>Bait</th>\n",
       "      <th>Mesra</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>به نام خداوند جان و خرد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>کز این برتر اندیشه بر نگذرد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>خداوند نام و خداوند جای</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>خداوند روزی ده رهنمای</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>خداوند کیوان و گَردان سپهر</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Chapter  Part  Bait  Mesra                         Text\n",
       "0        1     1     1      1      به نام خداوند جان و خرد\n",
       "1        1     1     1      2  کز این برتر اندیشه بر نگذرد\n",
       "2        1     1     2      1      خداوند نام و خداوند جای\n",
       "3        1     1     2      2        خداوند روزی ده رهنمای\n",
       "4        1     1     3      1   خداوند کیوان و گَردان سپهر"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./temp/shahname.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "befed0ee-3e26-47d9-9dd8-9d91a9a2054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جان و خرد\n",
      "کز این برتر اندیشه بر نگذرد\n",
      "خداوند نام و خداوند جای\n",
      "خداوند روزی ده رهنمای\n",
      "خداوند کیوان و گَردان سپهر\n",
      "فروزندهٔ ماه و ناهید و مهر\n",
      "ز نام و نشان و گمان برتر است\n",
      "نگارندهٔ بر شده پیکر است\n",
      "به بینندگان آفریننده را\n",
      "نبینی مرنجان دو بینن\n"
     ]
    }
   ],
   "source": [
    "text = '\\n'.join(df['Text'])\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703a2080-390f-4ff5-aa97-6a344edf3b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d07056-9552-40bb-aca3-cd5dcbf021ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ! ( ) :   « » ، ؛ ؟ ء آ أ ؤ ئ ا ب ت ث ج ح خ د ذ ر ز س ش ص ض ط ظ ع غ ف ق ل م ن ه و ي َ ُ ِ ّ ْ ٔ پ چ ژ ک گ ی ‌ "
     ]
    }
   ],
   "source": [
    "for v in vocab:\n",
    "    print(f'{v}', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b794b87f-c80d-43c6-aee1-fc507ab57020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a mapping from id to character, i.e. converts ids as integers into characters\n",
    "ids_to_chars = keras.layers.StringLookup(vocabulary=vocab, invert=True, \n",
    "                                        mask_token=None)\n",
    "# Defines a mapping from character to id, i.e. converts characters into ids as integers\n",
    "ids_from_chars = keras.layers.StringLookup(vocabulary=vocab, invert=False, \n",
    "                                          mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55e63eb4-c558-4706-a11b-4d06551100f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNK] \n",
      "   ! ( ) :   « » ، ؛ ؟ ء آ أ ؤ ئ ا ب ت ث ج ح خ د ذ ر ز س ش ص ض ط ظ ع غ ف ق ل م ن ه و ي َ ُ ِ ّ ْ ٔ پ چ ژ ک گ ی ‌ "
     ]
    }
   ],
   "source": [
    "# We have a UNK\n",
    "for v in ids_from_chars.get_vocabulary():\n",
    "    print(v, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "887bd609-fe58-4f9d-85f8-c739e2530244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!(): «،؟شطظ\n"
     ]
    }
   ],
   "source": [
    "# Given a list of ids, it will return a string\n",
    "def ids_to_text(ids):\n",
    "    return tf.strings.reduce_join(ids_to_chars(ids), axis=-1)\n",
    "\n",
    "print(ids_to_text([3, 4, 5, 6, 7, 8, 10, 12, 30, 33, 34]).numpy().decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7cce167-22ef-4d09-937c-ec5901d55194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([19 42  2 ... 27 56 41], shape=(2565041,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Convert all of the text into numbers, i.e. ids\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "print(all_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9540c51-8fb3-4de2-a428-df41c4e2627d",
   "metadata": {},
   "source": [
    "### Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fd8bb31-1f5b-453d-9b24-2441ed478b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 100\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19bf3242-ff51-46a3-8b79-62debb126ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(19, shape=(), dtype=int64)\n",
      "tf.Tensor(42, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(41, shape=(), dtype=int64)\n",
      "tf.Tensor(18, shape=(), dtype=int64)\n",
      "tf.Tensor(40, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(24, shape=(), dtype=int64)\n",
      "tf.Tensor(25, shape=(), dtype=int64)\n",
      "tf.Tensor(18, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "# EXAMPLE\n",
    "for i in ids_dataset.take(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b95808-b560-4037-90ca-19ccc97f3e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جان و خرد\n",
      "کز این برتر اندیشه بر نگذرد\n",
      "خداوند نام و خداوند جای\n",
      "خداوند روزی ده رهنمای\n",
      "خدا\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(batch_size=SEQUENCE_LENGTH + 1, drop_remainder=True, num_parallel_calls=AUTOTUNE)\n",
    "# EXAMPLE\n",
    "for ids in sequences.take(1):\n",
    "    print(ids_to_text(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f95daa7-d232-4c4a-9acc-0cee685ec296",
   "metadata": {},
   "source": [
    "#### Create ```(input, label)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0508b28-8b8d-4757-991c-aceb563a3e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A', 'l', 'i', 'r', 'e', 'z', 'a', ' ', 'K', 'a', 'm', 'y', 'a'],\n",
       " ['l', 'i', 'r', 'e', 'z', 'a', ' ', 'K', 'a', 'm', 'y', 'a', 'b'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "split_input_target(list('Alireza Kamyab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4003447-8821-41b4-b44a-088c674ce045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: به نام خداوند جان و خرد\n",
      "کز این برتر اندیشه بر نگذرد\n",
      "خداوند نام و خداوند جای\n",
      "خداوند روزی ده رهنمای\n",
      "خد\n",
      "Target: ه نام خداوند جان و خرد\n",
      "کز این برتر اندیشه بر نگذرد\n",
      "خداوند نام و خداوند جای\n",
      "خداوند روزی ده رهنمای\n",
      "خدا\n"
     ]
    }
   ],
   "source": [
    "dataset = sequences.map(split_input_target, num_parallel_calls=AUTOTUNE)\n",
    "# EXAMPLE\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input:', ids_to_text(input_example).numpy().decode('utf-8'))\n",
    "    print('Target:', ids_to_text(target_example).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268640c1-9452-47bb-a71f-3a18cbebba5d",
   "metadata": {},
   "source": [
    "#### Creating training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "261f23b5-9266-4848-926d-341bea4ee17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Since we are creating a stateful model, we should NOT shuffle\n",
    "dataset = dataset.batch(BATCH_SIZE, num_parallel_calls=AUTOTUNE, drop_remainder=True)\n",
    "dataset = dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0dd8eff-74a9-45f5-a787-18d9d3736173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of vocabulary in StringLoopup Layer\n",
    "VOCAB_SIZE = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "# Number of RNN units\n",
    "RNN_UNITS = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f25958ca-be4b-4124-8ae1-4dc8c45b650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(self, vocabulary_size, embedding_dim, rnn_units):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = keras.layers.Embedding(input_dim=vocabulary_size, output_dim=embedding_dim)\n",
    "        self.gru = keras.layers.GRU(units=rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = keras.layers.Dense(vocabulary_size)\n",
    "        \n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fba6f903-9c6b-41e5-ab87-45359685aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    rnn_units=RNN_UNITS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c3a2eb-63d2-450c-a9e6-b658549fd40b",
   "metadata": {},
   "source": [
    "#### Try the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6525bfa-5052-41e9-ac61-a16fefc5752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 58) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4bcc6ed-f62c-48c9-9f22-4d1c1024d1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  580       \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  12656640  \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  118842    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12776062 (48.74 MB)\n",
      "Trainable params: 12776062 (48.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54b24f05-081f-4e6e-8223-1b59e86cc0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indicies = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indicies = tf.squeeze(sampled_indicies, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a77c8a26-871e-476e-80f6-400bba7aa518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53, 19, 46, 57, 14, 45,  3,  0, 18, 22, 10, 17,  1, 19, 55, 35, 35,\n",
       "       51, 28, 10,  9, 37, 12, 38, 22, 17, 22, 56, 56, 39, 21, 39, 21, 56,\n",
       "       38, 54, 20, 56, 27, 19, 39, 24, 29, 11, 36, 35, 31, 36, 54,  7, 33,\n",
       "       15, 12, 34, 12, 25, 18, 38, 45, 22, 12, 50, 41, 26,  7, 18, 22, 41,\n",
       "       24, 28,  2, 24, 46, 22, 39, 12,  3, 52, 11, 32, 19, 33, 24, 28, 50,\n",
       "       38, 52, 24, 19, 51,  4, 52,  7, 31, 25,  1, 26, 15, 22, 25])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0e48ac5-5fb5-4496-9846-f0f1b212e580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: به نام خداوند جان و خرد\n",
      "کز این برتر اندیشه بر نگذرد\n",
      "خداوند نام و خداوند جای\n",
      "خداوند روزی ده رهنمای\n",
      "خد\n",
      "NEXT CHAR: ژبُ‌آَ![UNK]اج،ئ\n",
      "بگععپز،»ف؟قجئجییلثلثیقکتیربلخس؛غعصغک طأ؟ظ؟داقَج؟ٔنذ اجنخز خُجل؟!چ؛ضبطخزٔقچخبپ(چ صد\n",
      "ذأجد\n"
     ]
    }
   ],
   "source": [
    "print('INPUT:',ids_to_text(input_example_batch[0]).numpy().decode('utf-8'))\n",
    "print('NEXT CHAR:', ids_to_text(sampled_indicies).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06f694-5376-462a-a941-ecd90b1fd501",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aa52a9c-7a20-4a27-a252-23bc1dec8789",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9342c076-e356-4270-a437-a387ee2f7e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dir = './temp/chpts/'\n",
    "checkpoint_prefix = os.path.join(checkpoints_dir, 'chpt_{epoch}')\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fcb8064-5b00-46d3-b483-0b88b53052c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710698505.229144   46236 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1710698505.757496   46235 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/396 [==============================] - 50s 120ms/step - loss: 2.6338\n",
      "Epoch 2/30\n",
      "396/396 [==============================] - 47s 118ms/step - loss: 1.9455\n",
      "Epoch 3/30\n",
      "396/396 [==============================] - 47s 119ms/step - loss: 1.6312\n",
      "Epoch 4/30\n",
      "396/396 [==============================] - 47s 119ms/step - loss: 1.4627\n",
      "Epoch 5/30\n",
      "396/396 [==============================] - 47s 120ms/step - loss: 1.3492\n",
      "Epoch 6/30\n",
      "396/396 [==============================] - 47s 120ms/step - loss: 1.2553\n",
      "Epoch 7/30\n",
      "396/396 [==============================] - 47s 120ms/step - loss: 1.1630\n",
      "Epoch 8/30\n",
      "396/396 [==============================] - 47s 120ms/step - loss: 1.0639\n",
      "Epoch 9/30\n",
      "396/396 [==============================] - 48s 120ms/step - loss: 0.9702\n",
      "Epoch 10/30\n",
      "396/396 [==============================] - 48s 120ms/step - loss: 0.9075\n",
      "Epoch 11/30\n",
      "396/396 [==============================] - 48s 120ms/step - loss: 0.8690\n",
      "Epoch 12/30\n",
      "396/396 [==============================] - 48s 120ms/step - loss: 0.8325\n",
      "Epoch 13/30\n",
      "396/396 [==============================] - 48s 120ms/step - loss: 0.7944\n",
      "Epoch 14/30\n",
      "396/396 [==============================] - 48s 120ms/step - loss: 0.7694\n",
      "Epoch 15/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.7294\n",
      "Epoch 16/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.7023\n",
      "Epoch 17/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6917\n",
      "Epoch 18/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6903\n",
      "Epoch 19/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6792\n",
      "Epoch 20/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6715\n",
      "Epoch 21/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6782\n",
      "Epoch 22/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6689\n",
      "Epoch 23/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6616\n",
      "Epoch 24/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6659\n",
      "Epoch 25/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6606\n",
      "Epoch 26/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6721\n",
      "Epoch 27/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6612\n",
      "Epoch 28/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6693\n",
      "Epoch 29/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6535\n",
      "Epoch 30/30\n",
      "396/396 [==============================] - 48s 121ms/step - loss: 0.6625\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2fb37-fa80-4c93-9634-3feec16917cc",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1ab8dc0-c598-44dc-aed3-a9763f2fb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, ids_to_chars, ids_from_chars, temperature=1.0):\n",
    "        super(OneStep, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.ids_to_chars = ids_to_chars\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"[UNK]\" from being generated\n",
    "        ## This \"[:, None]\" thing is used to add another dim to skip_ids\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put -inf at each bad index\n",
    "            values=[-float('inf')] * len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model\n",
    "        ## Predicted logits shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states, return_state=True)\n",
    "\n",
    "        # Only use the last prediction\n",
    "        predicted_logits = predicted_logits[:, -1, :] # This means last sequence (i.e. last character)\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "\n",
    "        # Apply the prediction mask\n",
    "        predicted_logits += self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.ids_to_chars(predicted_ids)\n",
    "\n",
    "        # Return the characters and model states\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdd1678a-94f2-469a-858c-6bda6c331c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, ids_to_chars, ids_from_chars, temperature=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "043564b9-ee06-4b56-b32c-1e7ec8305a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جای نشای\n",
      "چو مهتان یکی شاه خیره بمان\n",
      "بدرید داننده شهر دار\n",
      "کز آن ماه‌ای کار میساد و وار\n",
      "ز باغار مردم که کردی تبار\n",
      "همیشه بزرگان و گاه مهان\n",
      "به هر جایگاهی رکان اندر اوی\n",
      "شنیدی که بر خارست بود پاک\n",
      "تو شادان و خونی مکن ز آختا\n",
      "بران لشکر گشنه آن تیز کم\n",
      "جهاندار خیزد میان به زس\n",
      "ببینوش پس گفت کای پادشا\n",
      "من این نامه در کار گردی تو گرد\n",
      "همه دل نخواهد شکند از میان\n",
      "چنین گفت کاین رنج داری به رزم\n",
      "که هر بود روزی به من بر گذشت\n",
      "مجای آن از اندیشه بر مرد دست\n",
      "تو گردیم از ایشان سراسر بخرس\n",
      "هر آنکس که جانم به تخت و کلاه\n",
      "توبر گشتم اندر جهان کس نبود\n",
      "که خورشید تابان مرا رفته بود\n",
      "ازان کاخ آشای تا پاسخ نهزد\n",
      "همی رفت پویان ز بی‌تند و دود\n",
      "یکی داغ دیگر سر اندر فریب\n",
      "همه بودنیها که و تن به تیر\n",
      "به مشت و چباغ و به چرخ بلند\n",
      "ز تمریکی و دهد زنهار درد\n",
      "چنین گفت شیروی و پاغوز خال\n",
      "نگویی مرا نیز فرخ مباد\n",
      "همه مهربان موبد ایزدیست\n",
      "کجا اندرین باره چرزی کسی\n",
      "نخستین مه و مرگ نا باد سرد\n",
      "ببادا به من بر به زندان بود\n",
      "بگرد جهان تنگ و زیرد مبود\n",
      "سر بدسگاران برو ناگزیر\n",
      "نهانی نیاطت به روز نبرد\n",
      "به خاک اندر آرم ز بهرام دید\n",
      "شد از جادوی با سپاهی گران\n",
      "بیام \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Run time: 2.96054744720459\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['به نام خداوند'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n\\n')\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7acee01-cc43-4a3f-8d07-8e6e471e0e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
