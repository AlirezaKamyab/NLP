{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b6ce471-882e-4d86-968c-ca9625ecae21",
   "metadata": {},
   "source": [
    "# Analogy Using Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37f4cd2-c2a0-4e97-9ae9-5fd6ed692756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d4b1de-a816-4aee-8d79-3aa7e51802a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dir = './temp'\n",
    "embedding_index = {}\n",
    "with open(os.path.join(glove_dir, 'glove.6B.100d.txt'), 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac25c0b-6f04-494a-8a25-4ccb284c0c6f",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "In data analysis, **cosine similarity** is a measure of similarity between two non-zero vectors defined in an inner product space. Cosine similarity is the cosine of the angle between the vectors; that is, it is the dot product of the vectors divided by the product of their lengths. It follows that the cosine similarity does not depend on the magnitudes of the vectors, but only on their angle. The cosine similarity always belongs to the interval $[-1, 1]$. For example, two proportional vectors have a cosine similarity of $1$, two orthogonal vectors have a similarity of $0$, and two opposite vectors have a similarity of $-1$. In some contexts, the component values of the vectors cannot be negative, in which case the cosine similarity is bounded in $[0, 1]$\n",
    "\n",
    "### Definition\n",
    "The cosine of two non-zero vectors can be derived by using the Euclidean dot product formula:\n",
    "$$\n",
    "\\begin{equation}\n",
    "    A \\cdot B = \\lVert A \\rVert \\lVert B \\rVert cos(\\theta)\n",
    "\\end{equation}\n",
    "$$\n",
    "Given two $n$-dimensional vectors of attributes, $\\mathbf{A}$ and $\\mathbf{B}$, the cosine similarity, $cos(\\theta)$, is represented using a dot product and magnitude as:\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\text{Cosine Similarity} = S_C(A, B) &= cos(\\theta)\\\\\n",
    "    &= \\frac{\\mathbf{A \\cdot B}}{\\lVert \\mathbf{A} \\rVert \\lVert \\mathbf{B} \\rVert}\\\\\n",
    "    &= \\frac{\\sum_{i=1}^{n}A_iB_i}{\\sqrt{\\sum_{i=1}^{n}A_i^2} \\cdot \\sqrt{\\sum_{i = 1}^{n}B_i^2}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fedd76e9-cf78-41c5-add5-db6e82355b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(u, v):\n",
    "    dot = np.dot(u, v.T)\n",
    "    length_prod = np.sqrt(np.sum(np.square(u), axis=-1)) * np.sqrt(np.sum(np.square(v), axis=-1))\n",
    "    return dot / (length_prod + 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae5cc4de-3c50-4c6a-b5be-87f6ff13cc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of (father, mother) is 0.8656660919003184\n",
      "Cosine similarity of (ball, crocodile) is 0.1520657243738079\n",
      "Cosine similarity of (france - paris, iran - tehran) is 0.6854124336246552\n"
     ]
    }
   ],
   "source": [
    "father = embedding_index['father']\n",
    "mother = embedding_index['mother']\n",
    "ball = embedding_index['ball']\n",
    "crocodile = embedding_index['crocodile']\n",
    "france = embedding_index['france']\n",
    "tehran = embedding_index['tehran']\n",
    "paris = embedding_index['paris']\n",
    "iran = embedding_index['iran']\n",
    "print('Cosine similarity of (father, mother) is', similarity(father, mother))\n",
    "print('Cosine similarity of (ball, crocodile) is', similarity(ball, crocodile))\n",
    "print('Cosine similarity of (france - paris, iran - tehran) is', similarity(france - paris, iran - tehran))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59c803-e26e-43be-ae03-58f28f2eb291",
   "metadata": {},
   "source": [
    "## Word Analogy Task\n",
    "In the work analogy task, we complete the sentence\n",
    "<font color=\"red\">\n",
    "\"a is to b as c is to ____\"\n",
    "<font color=\"black\">. An example is \n",
    "<font color=\"red\">\"man is to woman as king is to queen\"\n",
    "<font color=\"black\">. In detail, we are trying to find a word $d$, such that the associated word vectors $e_a, e_b, e_c, e_d$ are related in the following manner: $e_b - e_a \\approx e_d - e_c$. We will measure the similarity between $e_b - e_a$ and $e_d - e_c$ using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa472d05-3ffc-4180-93fa-1955c0cb484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(word_a, word_b, word_c, embedding_index):\n",
    "    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "    e_a, e_b, e_c = embedding_index[word_a], embedding_index[word_b], embedding_index[word_c]\n",
    "    words = np.array(list(embedding_index.keys()))\n",
    "\n",
    "    # get index of each word\n",
    "    ## This is done so to avoid word_d being the same thing\n",
    "    index_a = np.argmax(words == word_a)\n",
    "    index_b = np.argmax(words == word_b)\n",
    "    index_c = np.argmax(words == word_c)\n",
    "    \n",
    "    embedding_matrix = np.array(list(embedding_index.values()), dtype='float32')\n",
    "    part_1 = e_b - e_a\n",
    "    part_2 = embedding_matrix - e_c\n",
    "    similarities = similarity(part_2, part_1)\n",
    "    # avoid word_d to be the same word as word_a, word_b and word_c\n",
    "    similarities[[index_a, index_b, index_c]] = -100\n",
    "    # select the most similar word\n",
    "    selected_word = words[np.argmax(similarities)]\n",
    "    return selected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de557b8-86dc-4cf9-a93b-50e5a7e1bc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iranian'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('china', 'chinese', 'iran', embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce278c6c-af34-4d1f-b754-a06ed2229dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tehran'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('india', 'delhi', 'iran', embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f322fc0-9806-4fc6-b8f9-a517473e44c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'girl'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('man', 'woman', 'boy', embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00bfec68-2615-4568-bb41-3906d5f578bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bigger'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('small', 'smaller', 'big', embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abeeb6c1-8b10-42f3-91f6-28bc90dd2e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'low-income'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('man', 'hardworking', 'women', embedding_index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58ed0d7d-d14c-49be-9a9a-9fae3252d7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inuktitut'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('iran', 'farsi', 'canada', embedding_index) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
