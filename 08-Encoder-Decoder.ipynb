{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8922bbc8-ec99-4b3c-b8ec-839d197849a4",
   "metadata": {},
   "source": [
    "# Encoder/Decoder (Seq2Seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e765c5-da37-42ec-8ef7-e3c757bea72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 05:20:17.727464: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-31 05:20:17.727493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-31 05:20:17.728361: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc7de4-c897-4fbf-995e-8b497013a5a7",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c24ce51-fd5f-4fad-86f4-03e253d484fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_MAX_LENGTH = 13\n",
    "TARGET_MAX_LENGTH = 5\n",
    "EOS = '<EOS>'\n",
    "ops = ['+', '-', '*']\n",
    "exps = [['<E>', '<OP>', '<E>'], ['<N>', '<OP>', '<E>'], ['(', '<E>', '<OP>', '<E>', ')'], ['<N>']]\n",
    "\n",
    "\n",
    "def flatten(lst:list) -> list:\n",
    "    flattened = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            flattened.extend(item)\n",
    "        else:\n",
    "            flattened.append(item)\n",
    "    return flattened\n",
    "    \n",
    "\n",
    "def make_expression(expression, depth=0, min_depth=0, max_depth=3) -> list:\n",
    "    if len(expression) == 0: expression.append('<E>')\n",
    "    if '<E>' not in expression: return expression\n",
    "    if depth == max_depth:\n",
    "        for i in range(len(expression)):\n",
    "            if expression[i] == '<E>': expression[i] = '<N>'\n",
    "        return expression\n",
    "\n",
    "    while '<E>' in expression:\n",
    "        if depth > min_depth:\n",
    "            i = np.random.choice(len(exps))\n",
    "        else:\n",
    "            i = np.random.choice(len(exps[:-1]))\n",
    "        ei = expression.index('<E>')\n",
    "        expression[ei] = exps[i]\n",
    "    expression = flatten(expression)\n",
    "    return make_expression(expression, depth=depth + 1, min_depth=min_depth, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863d5db2-fd75-4cf5-b673-146cf2ef8bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_data(low=0, high=10, min_depth=0, max_depth=2):\n",
    "    expression = []\n",
    "    expression = make_expression(expression, min_depth=min_depth, max_depth=max_depth)\n",
    "    for i in range(len(expression)):\n",
    "        if expression[i] == '<N>':\n",
    "            num = np.random.randint(low, high)\n",
    "            expression[i] = str(num)\n",
    "        elif expression[i] == '<OP>':\n",
    "            op = np.random.choice(ops)\n",
    "            expression[i] = op\n",
    "    x = ''.join(expression)\n",
    "    y = str(eval(x))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cebf50bc-0fae-4bb3-9d1f-427c0b90a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_samples=1000, low=0, high=10, min_depth=1, max_depth=2):\n",
    "    source = []\n",
    "    target = []\n",
    "    cnt = 0\n",
    "    while cnt < num_samples:\n",
    "        try:\n",
    "            xi, yi = generate_single_data(low, high, min_depth=min_depth, max_depth=max_depth)\n",
    "            source.append(xi)\n",
    "            target.append(yi)\n",
    "            cnt += 1\n",
    "            if cnt % 1000 == 0:\n",
    "                print(f'\\rCount: {cnt:>9}', end='')\n",
    "        except:\n",
    "            pass\n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48bf9aba-3b7f-4862-9ada-1cf23d3d52e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:    200000"
     ]
    }
   ],
   "source": [
    "source1, target1 = generate_data(num_samples=200_000, min_depth=1, max_depth=2)\n",
    "source2, target2 = generate_data(num_samples=200_000, min_depth=1, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9979e89-0b6b-41f9-a40f-7b38361531e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = np.concatenate([source1, source2], axis=-1)\n",
    "target = np.concatenate([target1, target2], axis=-1)\n",
    "\n",
    "idx = [x for x in range(len(source))]\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "source = source[idx]\n",
    "target = target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4e2f042-df13-4d05-a2e0-50abb5dad5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 is the maximum length\n"
     ]
    }
   ],
   "source": [
    "max_length_generated = 0\n",
    "for xi, yi in zip(source, target):\n",
    "    #print(xi, '=', yi)\n",
    "    max_length_generated = max(len(xi.strip()), max_length_generated)\n",
    "\n",
    "print(max_length_generated, 'is the maximum length')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce5ab5-72cf-4b70-a4f9-09cca4b36f31",
   "metadata": {},
   "source": [
    "## Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d557615f-e64c-40f6-b74e-307919ffcc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of source vocabulary is 16\n"
     ]
    }
   ],
   "source": [
    "source_vocab = [EOS] + list('0123456789()') + ops\n",
    "char_to_id_source = tf.keras.layers.StringLookup(vocabulary=source_vocab, num_oov_indices=0)\n",
    "id_to_char_source = tf.keras.layers.StringLookup(vocabulary=source_vocab, num_oov_indices=0, invert=True)\n",
    "SOURCE_VOCAB_SIZE = len(char_to_id_source.get_vocabulary())\n",
    "print(f'Length of source vocabulary is {SOURCE_VOCAB_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f5fcef-6f79-4b90-a3aa-b1b55d7b5799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of target vocabulary is 12\n"
     ]
    }
   ],
   "source": [
    "target_vocab = [EOS] + list('-0123456789')\n",
    "char_to_id_target = tf.keras.layers.StringLookup(vocabulary=target_vocab, num_oov_indices=0)\n",
    "id_to_char_target = tf.keras.layers.StringLookup(vocabulary=target_vocab, num_oov_indices=0, invert=True)\n",
    "TARGET_VOCAB_SIZE = len(char_to_id_target.get_vocabulary())\n",
    "print(f'Length of target vocabulary is {TARGET_VOCAB_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e630b61-8474-4224-a8df-942babb8fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_id_source(str_num):\n",
    "    return char_to_id_source(tf.strings.unicode_split(str_num, 'UTF-8'))\n",
    "\n",
    "def ids_to_str_source(ids):\n",
    "    return tf.strings.reduce_join(id_to_char_source(ids), axis=-1)\n",
    "\n",
    "def str_to_id_target(str_num):\n",
    "    return char_to_id_target(tf.strings.unicode_split(str_num, 'UTF-8'))\n",
    "\n",
    "def ids_to_str_target(ids):\n",
    "    return tf.strings.reduce_join(id_to_char_target(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6a166f8-b317-4adb-aa62-bbaaabc0f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_SOURCE_INT = char_to_id_source(EOS)\n",
    "EOS_TARGET_INT = char_to_id_target(EOS)\n",
    "SHUFFLE_BUFFER = 1000\n",
    "BATCH_SIZE = 128\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def get_dataset_ids(source, target):\n",
    "    source = str_to_id_source(source)\n",
    "    target = str_to_id_target(target)\n",
    "    return source, target\n",
    "\n",
    "\n",
    "def pad_sequences(source, target):\n",
    "    source_len = tf.shape(source)[-1]\n",
    "    target_len = tf.shape(target)[-1]\n",
    "    source = tf.pad(source, [[SOURCE_MAX_LENGTH - source_len, 0]], constant_values=EOS_SOURCE_INT)\n",
    "    target = tf.pad(target, [[1, TARGET_MAX_LENGTH - target_len - 1]], constant_values=EOS_TARGET_INT)\n",
    "    return source, target\n",
    "\n",
    "\n",
    "def get_source_target_label(source, target):\n",
    "    label = target[1:]\n",
    "    target = target[:-1]\n",
    "    return (source, target), label\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((source, target))\n",
    "dataset = dataset.map(get_dataset_ids, num_parallel_calls=AUTOTUNE)\n",
    "dataset = dataset.map(pad_sequences, num_parallel_calls=AUTOTUNE)\n",
    "dataset = dataset.map(get_source_target_label, num_parallel_calls=AUTOTUNE)\n",
    "dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "dataset = dataset.batch(BATCH_SIZE, num_parallel_calls=AUTOTUNE)\n",
    "dataset = dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63f70d29-44f9-4760-a86a-b812662df2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+6+3-0 = 10\n",
      "2-5-5 = -8\n",
      "(2*0) = 0\n",
      "8-(1*1) = 7\n",
      "(8-0) = 8\n",
      "3+6 = 9\n",
      "5*(8+5) = 65\n",
      "(8*2)*6+3 = 99\n",
      "9+1 = 10\n",
      "(8+4) = 12\n",
      "(9*3) = 27\n",
      "7+2*4 = 15\n",
      "(0-2+(0*8)) = -2\n",
      "0-5 = -5\n",
      "9*9 = 81\n",
      "8*4 = 32\n",
      "3-9 = -6\n",
      "3+0 = 3\n",
      "3-(1*9) = -6\n",
      "3+0 = 3\n",
      "7-6 = 1\n",
      "8+3-0-7 = 4\n",
      "6*7*9*6 = 226\n",
      "3-1 = 2\n",
      "(6+0) = 6\n",
      "7-3-3 = 1\n",
      "5-8-(3+5) = -11\n",
      "0*1*1*4 = 0\n",
      "(7-8) = -1\n",
      "2+5 = 7\n"
     ]
    }
   ],
   "source": [
    "for (s, t), y in dataset.take(30):\n",
    "    i = np.random.choice(len(s))\n",
    "    s = s[i]\n",
    "    t = t[i]\n",
    "    print(ids_to_str_source(s).numpy().decode('utf-8').replace('<EOS>', ''), '=', \n",
    "          ids_to_str_target(t).numpy().decode('utf-8').replace('<EOS>', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643b0b5-ce4e-47d6-9498-2c1cf3742990",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c6f8191-2cad-425e-ad30-f5d045ca22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, TimeDistributed, RepeatVector, Dense, Embedding, Input, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.regularizers import L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab6df6b0-54e3-4e4a-aec6-ac010ea10f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_EMBEDDING_DIM = 20\n",
    "TARGET_EMBEDDING_DIM = 10\n",
    "UNITS = 256\n",
    "\n",
    "class Encoder(Layer):\n",
    "    def __init__(self, units, embedding_dim, vocab_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.units = units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim)\n",
    "        self.lstm1 = LSTM(self.units, return_state=True, return_sequences=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x, h, c = self.lstm1(x)\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class Decoder(Layer):\n",
    "    def __init__(self, units, embedding_dim, vocab_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.units = units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim,)\n",
    "        self.lstm1 = LSTM(self.units, return_sequences=True, return_state=True)        \n",
    "\n",
    "    def call(self, inputs, h, c, return_states=False):\n",
    "        x = self.embedding(inputs)\n",
    "        x, h, c = self.lstm1(x, initial_state=(h, c))\n",
    "        if return_states:\n",
    "            return x, h, c\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b6598a0-ffb7-4c51-aac4-85f24924ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self, units, source_embedding_dim, target_embedding_dim, source_vocab_size, target_vocab_size, **kwargs):\n",
    "        super(MyModel, self).__init__(**kwargs)\n",
    "\n",
    "        self.units = units\n",
    "        self.source_embedding_dim = source_embedding_dim\n",
    "        self.target_embedding_dim = target_embedding_dim\n",
    "        self.source_vocab_size = source_vocab_size\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "\n",
    "        self.encoder = Encoder(self.units, self.source_embedding_dim, self.source_vocab_size)\n",
    "        self.decoder = Decoder(self.units, self.target_embedding_dim, self.target_vocab_size)\n",
    "        self.classifier = Dense(units=self.target_vocab_size, activation='softmax')\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        encoder_inputs, decoder_inputs = inputs\n",
    "        h, c = self.encoder(encoder_inputs)\n",
    "        x = self.decoder(decoder_inputs, h, c)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e240ed67-e88e-40fc-b2ff-95245028bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(units=UNITS, source_embedding_dim=SOURCE_EMBEDDING_DIM, target_embedding_dim=TARGET_EMBEDDING_DIM,\n",
    "               source_vocab_size=SOURCE_VOCAB_SIZE, target_vocab_size=TARGET_VOCAB_SIZE)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "def get_scheduler(initial_learning_rate, weight=0.9):\n",
    "    def scheduler(epoch):\n",
    "        return initial_learning_rate * weight ** epoch\n",
    "\n",
    "    return scheduler\n",
    "\n",
    "scheduler = get_scheduler(1e-2, weight=0.97)\n",
    "learning_rate_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fee7e9c-3c8b-464d-af97-5bb0b4eba4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711849855.415036   27233 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 18s 5ms/step - loss: 0.2425 - accuracy: 0.9107 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0975 - accuracy: 0.9614 - lr: 0.0097\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0756 - accuracy: 0.9698 - lr: 0.0094\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0669 - accuracy: 0.9735 - lr: 0.0091\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0580 - accuracy: 0.9771 - lr: 0.0089\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0543 - accuracy: 0.9788 - lr: 0.0086\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0490 - accuracy: 0.9810 - lr: 0.0083\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0466 - accuracy: 0.9820 - lr: 0.0081\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0420 - accuracy: 0.9837 - lr: 0.0078\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0395 - accuracy: 0.9848 - lr: 0.0076\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0379 - accuracy: 0.9857 - lr: 0.0074\n",
      "Epoch 12/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0343 - accuracy: 0.9868 - lr: 0.0072\n",
      "Epoch 13/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0330 - accuracy: 0.9874 - lr: 0.0069\n",
      "Epoch 14/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0318 - accuracy: 0.9880 - lr: 0.0067\n",
      "Epoch 15/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0294 - accuracy: 0.9889 - lr: 0.0065\n",
      "Epoch 16/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0273 - accuracy: 0.9897 - lr: 0.0063\n",
      "Epoch 17/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0258 - accuracy: 0.9902 - lr: 0.0061\n",
      "Epoch 18/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0244 - accuracy: 0.9908 - lr: 0.0060\n",
      "Epoch 19/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0230 - accuracy: 0.9914 - lr: 0.0058\n",
      "Epoch 20/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0216 - accuracy: 0.9920 - lr: 0.0056\n",
      "Epoch 21/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0205 - accuracy: 0.9924 - lr: 0.0054\n",
      "Epoch 22/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0196 - accuracy: 0.9927 - lr: 0.0053\n",
      "Epoch 23/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0180 - accuracy: 0.9934 - lr: 0.0051\n",
      "Epoch 24/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0179 - accuracy: 0.9935 - lr: 0.0050\n",
      "Epoch 25/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0164 - accuracy: 0.9940 - lr: 0.0048\n",
      "Epoch 26/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0154 - accuracy: 0.9943 - lr: 0.0047\n",
      "Epoch 27/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0143 - accuracy: 0.9947 - lr: 0.0045\n",
      "Epoch 28/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0137 - accuracy: 0.9950 - lr: 0.0044\n",
      "Epoch 29/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0126 - accuracy: 0.9954 - lr: 0.0043\n",
      "Epoch 30/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0118 - accuracy: 0.9958 - lr: 0.0041\n",
      "Epoch 31/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0114 - accuracy: 0.9959 - lr: 0.0040\n",
      "Epoch 32/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0108 - accuracy: 0.9962 - lr: 0.0039\n",
      "Epoch 33/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0098 - accuracy: 0.9965 - lr: 0.0038\n",
      "Epoch 34/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0093 - accuracy: 0.9968 - lr: 0.0037\n",
      "Epoch 35/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0091 - accuracy: 0.9968 - lr: 0.0036\n",
      "Epoch 36/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0078 - accuracy: 0.9973 - lr: 0.0034\n",
      "Epoch 37/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0073 - accuracy: 0.9975 - lr: 0.0033\n",
      "Epoch 38/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0073 - accuracy: 0.9975 - lr: 0.0032\n",
      "Epoch 39/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0068 - accuracy: 0.9977 - lr: 0.0031\n",
      "Epoch 40/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0063 - accuracy: 0.9979 - lr: 0.0030\n",
      "Epoch 41/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0056 - accuracy: 0.9982 - lr: 0.0030\n",
      "Epoch 42/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0053 - accuracy: 0.9982 - lr: 0.0029\n",
      "Epoch 43/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0048 - accuracy: 0.9984 - lr: 0.0028\n",
      "Epoch 44/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0047 - accuracy: 0.9985 - lr: 0.0027\n",
      "Epoch 45/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0043 - accuracy: 0.9986 - lr: 0.0026\n",
      "Epoch 46/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0039 - accuracy: 0.9988 - lr: 0.0025\n",
      "Epoch 47/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0036 - accuracy: 0.9989 - lr: 0.0025\n",
      "Epoch 48/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0035 - accuracy: 0.9989 - lr: 0.0024\n",
      "Epoch 49/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0033 - accuracy: 0.9990 - lr: 0.0023\n",
      "Epoch 50/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0028 - accuracy: 0.9992 - lr: 0.0022\n",
      "Epoch 51/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0026 - accuracy: 0.9993 - lr: 0.0022\n",
      "Epoch 52/100\n",
      "3125/3125 [==============================] - 16s 5ms/step - loss: 0.0027 - accuracy: 0.9992 - lr: 0.0021\n",
      "Epoch 53/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0023 - accuracy: 0.9993 - lr: 0.0021\n",
      "Epoch 54/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0021 - accuracy: 0.9994 - lr: 0.0020\n",
      "Epoch 55/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0021 - accuracy: 0.9995 - lr: 0.0019\n",
      "Epoch 56/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0018 - accuracy: 0.9995 - lr: 0.0019\n",
      "Epoch 57/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0018 - accuracy: 0.9995 - lr: 0.0018\n",
      "Epoch 58/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - lr: 0.0018\n",
      "Epoch 59/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - lr: 0.0017\n",
      "Epoch 60/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0013 - accuracy: 0.9997 - lr: 0.0017\n",
      "Epoch 61/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0011 - accuracy: 0.9997 - lr: 0.0016\n",
      "Epoch 62/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0012 - accuracy: 0.9997 - lr: 0.0016\n",
      "Epoch 63/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 0.0010 - accuracy: 0.9998 - lr: 0.0015\n",
      "Epoch 64/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 8.7645e-04 - accuracy: 0.9998 - lr: 0.0015\n",
      "Epoch 65/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 9.3973e-04 - accuracy: 0.9998 - lr: 0.0014\n",
      "Epoch 66/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 7.6390e-04 - accuracy: 0.9998 - lr: 0.0014\n",
      "Epoch 67/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 8.2361e-04 - accuracy: 0.9998 - lr: 0.0013\n",
      "Epoch 68/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 6.7721e-04 - accuracy: 0.9999 - lr: 0.0013\n",
      "Epoch 69/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 5.9258e-04 - accuracy: 0.9999 - lr: 0.0013\n",
      "Epoch 70/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 6.7375e-04 - accuracy: 0.9999 - lr: 0.0012\n",
      "Epoch 71/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 4.8494e-04 - accuracy: 0.9999 - lr: 0.0012\n",
      "Epoch 72/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 4.2787e-04 - accuracy: 0.9999 - lr: 0.0012\n",
      "Epoch 73/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 4.9529e-04 - accuracy: 0.9999 - lr: 0.0011\n",
      "Epoch 74/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 3.8763e-04 - accuracy: 0.9999 - lr: 0.0011\n",
      "Epoch 75/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 3.4509e-04 - accuracy: 0.9999 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 3.5434e-04 - accuracy: 0.9999 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 3.3176e-04 - accuracy: 0.9999 - lr: 9.8776e-04\n",
      "Epoch 78/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 3.1116e-04 - accuracy: 1.0000 - lr: 9.5813e-04\n",
      "Epoch 79/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 1.7568e-04 - accuracy: 1.0000 - lr: 9.2938e-04\n",
      "Epoch 80/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 2.4573e-04 - accuracy: 1.0000 - lr: 9.0150e-04\n",
      "Epoch 81/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 1.7809e-04 - accuracy: 1.0000 - lr: 8.7446e-04\n",
      "Epoch 82/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 2.4307e-04 - accuracy: 1.0000 - lr: 8.4822e-04\n",
      "Epoch 83/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 1.3282e-04 - accuracy: 1.0000 - lr: 8.2278e-04\n",
      "Epoch 84/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 1.8002e-04 - accuracy: 1.0000 - lr: 7.9809e-04\n",
      "Epoch 85/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 1.2577e-04 - accuracy: 1.0000 - lr: 7.7415e-04\n",
      "Epoch 86/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 1.5427e-04 - accuracy: 1.0000 - lr: 7.5093e-04\n",
      "Epoch 87/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 7.0567e-05 - accuracy: 1.0000 - lr: 7.2840e-04\n",
      "Epoch 88/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 9.1781e-05 - accuracy: 1.0000 - lr: 7.0655e-04\n",
      "Epoch 89/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 1.2203e-04 - accuracy: 1.0000 - lr: 6.8535e-04\n",
      "Epoch 90/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 1.1311e-04 - accuracy: 1.0000 - lr: 6.6479e-04\n",
      "Epoch 91/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 6.9966e-05 - accuracy: 1.0000 - lr: 6.4485e-04\n",
      "Epoch 92/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 1.0673e-04 - accuracy: 1.0000 - lr: 6.2550e-04\n",
      "Epoch 93/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 6.0210e-05 - accuracy: 1.0000 - lr: 6.0674e-04\n",
      "Epoch 94/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 4.0223e-05 - accuracy: 1.0000 - lr: 5.8853e-04\n",
      "Epoch 95/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 6.3523e-05 - accuracy: 1.0000 - lr: 5.7088e-04\n",
      "Epoch 96/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 3.8770e-05 - accuracy: 1.0000 - lr: 5.5375e-04\n",
      "Epoch 97/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 2.9509e-05 - accuracy: 1.0000 - lr: 5.3714e-04\n",
      "Epoch 98/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 3.0364e-05 - accuracy: 1.0000 - lr: 5.2102e-04\n",
      "Epoch 99/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 3.1881e-05 - accuracy: 1.0000 - lr: 5.0539e-04\n",
      "Epoch 100/100\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 3.8511e-05 - accuracy: 1.0000 - lr: 4.9023e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=100, callbacks=[learning_rate_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e663cf07-a951-49ee-b6b1-97cbe0f25a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModel(Model):\n",
    "    def __init__(self, main_model):\n",
    "        super(PredictionModel, self).__init__()\n",
    "        \n",
    "        self.main_model = main_model\n",
    "        self.encoder = self.main_model.encoder\n",
    "        self.decoder = self.main_model.decoder\n",
    "        self.classifier = self.main_model.classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = str_to_id_source(inputs)[None, ...]\n",
    "        h, c = self.encoder(inputs)\n",
    "        tensor_arr = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "        tensor_arr = tensor_arr.write(0, char_to_id_target(EOS).numpy())\n",
    "        for cnt in range(1, TARGET_MAX_LENGTH + 1):\n",
    "            semi_complete = tensor_arr.stack()[None, ...]\n",
    "            x, = self.decoder(semi_complete, h, c)\n",
    "            x = self.classifier(x)\n",
    "            x = tf.argmax(x, axis=-1)\n",
    "            tensor_arr = tensor_arr.write(cnt, x[-1])\n",
    "        res = tensor_arr.stack()[None, 1:]\n",
    "        return ids_to_str_target(res).numpy()[0].decode('utf-8').replace(EOS, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084cce3-7b20-4a7b-94d9-1ce384b8ddee",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95816d39-9a14-4c91-9a7d-ee06904a7077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2+3*4 = 14\n",
      "(5+3) = 8\n",
      "2*(3+4) = 14\n",
      "5*(2+3)*(5+3) = 90\n",
      "(7+9)+8+7 = 31\n",
      "(1*5)+(9-2) = 12\n"
     ]
    }
   ],
   "source": [
    "pred_model = PredictionModel(model)\n",
    "\n",
    "test_source = [\n",
    "    '2+3*4', '(5+3)', '2*(3+4)', '5*(2+3)*(5+3)', '(7+9)+8+7', '(1*5)+(9-2)'\n",
    "]\n",
    "\n",
    "for i in range(len(test_source)):\n",
    "    res = pred_model(test_source[i])\n",
    "    print(test_source[i], '=', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d33cd3b7-6773-41dc-8bb9-4cac56ce4740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easy Ones\n",
      "9*1           =     9 and predicted     1\n",
      "(6*5)         =    30 and predicted    30\n",
      "5*6           =    30 and predicted    30\n",
      "7+6           =    13 and predicted    15\n",
      "(6*7)         =    42 and predicted    42\n",
      "(4+0)         =     4 and predicted     4\n",
      "3*6           =    18 and predicted    20\n",
      "3-2           =     1 and predicted     1\n",
      "2-0           =     2 and predicted     2\n",
      "0+4           =     4 and predicted     4\n",
      "3-9           =    -6 and predicted    -6\n",
      "2-9           =    -7 and predicted    -7\n",
      "5+6           =    11 and predicted    11\n",
      "5+9           =    14 and predicted    14\n",
      "0*2           =     0 and predicted     0\n",
      "(0-0)         =     0 and predicted     0\n",
      "6+8           =    14 and predicted    14\n",
      "(4+1)         =     5 and predicted     5\n",
      "(4*3)         =    12 and predicted    12\n",
      "8*9           =    72 and predicted    72\n",
      "\n",
      "Difficult ones\n",
      "4*2+0*9       =     8 and predicted     8\n",
      "2+5+5-4       =     8 and predicted     8\n",
      "7*7+2         =    51 and predicted    57\n",
      "((0-7)*1+2)   =    -5 and predicted    -5\n",
      "((7*9)-(7-3)) =    59 and predicted    59\n",
      "1*0+(3-0)     =     3 and predicted     3\n",
      "(1*4)-0-8     =    -4 and predicted    -4\n",
      "(4+0*(2-3))   =     4 and predicted     4\n",
      "1-3*6-0       =   -17 and predicted   -17\n",
      "(8+0*4*6)     =     8 and predicted     8\n",
      "6+(8-0)       =    14 and predicted    14\n",
      "(1*4*6-0)     =    24 and predicted    24\n",
      "(0+1+7*4)     =    29 and predicted    29\n",
      "9+5*3         =    24 and predicted    52\n",
      "(9+5+(5+3))   =    22 and predicted    22\n",
      "(2-5)-7+9     =    -1 and predicted    -1\n",
      "9-(8+2)       =    -1 and predicted     1\n",
      "6*(9-1)       =    48 and predicted    48\n",
      "6+8-9+3       =     8 and predicted     8\n",
      "(6+8)*(0+3)   =    42 and predicted    50\n"
     ]
    }
   ],
   "source": [
    "print('Easy Ones')\n",
    "for i in range(20):\n",
    "    test_source, test_target = generate_single_data(min_depth=1, max_depth=1)\n",
    "    pred = pred_model(test_source)\n",
    "    print(f'{test_source:<13} = {test_target:>5} and predicted {pred:>5}')\n",
    "\n",
    "print('\\nDifficult ones')\n",
    "for i in range(20):\n",
    "    test_source, test_target = generate_single_data(min_depth=1, max_depth=2)\n",
    "    pred = pred_model(test_source)\n",
    "    print(f'{test_source:<13} = {test_target:>5} and predicted {pred:>5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c29a3-78af-4613-aa2e-45578a5aef14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
